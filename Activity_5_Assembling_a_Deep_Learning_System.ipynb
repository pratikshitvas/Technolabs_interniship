{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 5: Assembling a Deep Learning System\n",
    "In this activity, we will train the first version of our LSTM model using Bitcoin daily closing prices. These prices will be organized using the weeks of both 2016 and 2017. We do that because we are interested in predicting the prices of a week's worth of trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 5\n",
    "\n",
    "#  Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import training dataset\n",
    "train = pd.read_csv('data/train_dataset.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(data, group_size=7):\n",
    "    \"\"\"Create distinct groups from a continuous series.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Series of continious observations.\n",
    "\n",
    "    group_size: int, default 7\n",
    "        Determines how large the groups are. That is,\n",
    "        how many observations each group contains.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Numpy array object. \n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for i in range(0, len(data), group_size):\n",
    "        sample = list(data[i:i + group_size])\n",
    "        if len(sample) == group_size:\n",
    "            samples.append(np.array(sample).reshape(1, group_size))\n",
    "    \n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find the remainder when the number of observations is divided by group size\n",
    "len(train) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create groups of 7 from our data.\n",
    "#  We drop the first two observations so that the\n",
    "#  number of total observations is divisible by the `group_size`.\n",
    "data = create_groups(train['close_point_relative_normalization'][2:].values)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reshape data into format expected by LSTM layer\n",
    "X_train = data[:-1, :].reshape(1, 76, 7)\n",
    "Y_validation = data[-1].reshape(1, 7)\n",
    "print(X_train.shape)\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load our previously trained model \n",
    "model = load_model('bitcoin_lstm_v0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#  Train the model\n",
    "history = model.fit(\n",
    "    x=X_train, y=Y_validation,\n",
    "    batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot loss function\n",
    "pd.Series(history.history['loss']).plot(figsize=(14, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Make predictions using X_train data\n",
    "predictions = model.predict(x=X_train)[0]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(series, last_value):\n",
    "    \"\"\"Denormalize the values for a given series.\n",
    "    \n",
    "    This uses the last value available (i.e. the last\n",
    "    closing price of the week before our prediction)\n",
    "    as a reference for scaling the predicted results.\n",
    "    \"\"\"\n",
    "    result = last_value * (series + 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Denormalize predictions\n",
    "last_weeks_value = train[train['date'] == train['date'][:-7].max()]['close'].values[0]\n",
    "\n",
    "denormalized_prediction = denormalize(predictions, last_weeks_value)\n",
    "denormalized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot denormalized predictions against actual predictions\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.plot(train['close'][-7:].values, label='Actual')\n",
    "plt.plot(denormalized_prediction, color='#d35400', label='Predicted')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_plot = np.zeros(len(train)-2)\n",
    "prediction_plot[:] = np.nan\n",
    "prediction_plot[-7:] = denormalized_prediction\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(train['close'][-30:].values, label='Actual')\n",
    "plt.plot(prediction_plot[-30:], color='#d35400', linestyle='--', label='Predicted')\n",
    "plt.axvline(30 - 7, color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "8ce0c2"
   },
   "outputs": [],
   "source": [
    "#  TASK:\n",
    "#  Save model to disk\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we have assembled a complete deep learning system: from data to prediction. The model created in this activity need a number of improvements before it can be considered useful. However, it serves as a great starting point from which we will continuously improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
