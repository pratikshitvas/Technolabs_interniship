{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "technolabas task 1",
      "provenance": [],
      "authorship_tag": "ABX9TyN7Q1idR1xCyIeJ9QaGITTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikshitvas/Technolabs_interniship/blob/main/technolabas_task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEIKzgT8ppHi",
        "outputId": "bf64e46c-5e84-4245-bbec-bfdaebd5547b"
      },
      "source": [
        "pip install tensorflow\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMzuWM4GpumC"
      },
      "source": [
        "# **CODE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luCjhvQXpzJa"
      },
      "source": [
        "\"\"\"Copyright 2017 Google, Inc. All Rights Reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "----\n",
        "Original script can be found at\n",
        "\n",
        "    https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial\n",
        "\n",
        "And is similar to the TensorFlow tutorial script found at\n",
        "\n",
        "    https://www.tensorflow.org/get_started/mnist/mechanics\n",
        "\"\"\"\n",
        "import tqdm\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#\n",
        "#  Script variables. Change these and observe\n",
        "#  how results change.\n",
        "#\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 2000\n",
        "\n",
        "\n",
        "#\n",
        "#  Script constants. Here we pull data available\n",
        "#  locally. The data contains both the sprites\n",
        "#  and the labels from the original MNIST dataset.\n",
        "#\n",
        "LOGDIR = \"mnist_example/\"\n",
        "LABELS = os.path.join(os.getcwd(), \"data/labels_1024.tsv\")\n",
        "SPRITES = os.path.join(os.getcwd(), \"data/sprite_1024.png\")\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load data form the MNIST dataset into memory.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TensorFlow object with dataset.\n",
        "    \"\"\"\n",
        "    if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
        "        raise ValueError(\"\"\"\n",
        "            Necessary data files were not found. Make sure the files\n",
        "\n",
        "                * labels_1024.tsv\n",
        "                * sprite_1024.png\n",
        "\n",
        "            are available in the same location where you run this script.\n",
        "            \"\"\")\n",
        "\n",
        "    return tf.contrib.learn.datasets.mnist.read_data_sets(\n",
        "        train_dir=LOGDIR + \"data\", one_hot=True)\n",
        "\n",
        "\n",
        "def convolutional_layer(input, size_in, size_out, name=\"convolutional\"):\n",
        "    \"\"\"Convoluted layer.\n",
        "\n",
        "    Create the weights and biases distributions.\n",
        "    Also define the convolution and the activation function (ReLU).\n",
        "    Finally, we create some histogram summaries useful for TensorBoard.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        W = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        convolution = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        activation = tf.nn.relu(convolution + B)\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return tf.nn.max_pool(activation, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "\n",
        "def fully_connected_layer(input, size_in, size_out, name=\"fully_connected\"):\n",
        "    \"\"\"Fully connected layer.\n",
        "\n",
        "    This defines the fully connected layer.\n",
        "    Different from the convolution layer, this layer does not\n",
        "    perform a convolution but only defines an activation function.\n",
        "    That function is also different from the convolution layer\n",
        "    by multipliying the input data with its weights plus the biases,\n",
        "    which is a much simpler activation function than ReLU.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        W = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        activation = tf.matmul(input, W) + B\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return activation\n",
        "\n",
        "\n",
        "def model(mnist, learning_rate, epochs=2000):\n",
        "    \"\"\"Neural network model used in the MNIST dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mnist: TensorFlow dataset object\n",
        "        MNIST dataset loaded using TensorFlow.\n",
        "\n",
        "    learning_rate: float\n",
        "        Learning rate at which the network should\n",
        "        create momentum.\n",
        "\n",
        "    epochs: int, default 2000\n",
        "        Number of epochs to train the model with.\n",
        "    \"\"\"\n",
        "    name = \"MNIST-model/lr={}-epochs={}\".format(learning_rate, epochs)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    sess = tf.Session()\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
        "    X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
        "    tf.summary.image('input', X_image, 3)\n",
        "\n",
        "    Y = tf.placeholder(tf.float32, shape=[None, 10], name=\"Labels\")\n",
        "\n",
        "    #\n",
        "    #  Convolutional layer treatment. We use a single convolutional layer.\n",
        "    #\n",
        "    convolution = convolutional_layer(X_image, 1, 64, \"Convolution_Layer\")\n",
        "    convolution_output = tf.nn.max_pool(convolution, ksize=[1, 2, 2, 1],\n",
        "                                        strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "    flattened = tf.reshape(convolution_output, [-1, 7 * 7 * 64])\n",
        "\n",
        "    #\n",
        "    #  Fully-connected layer treatment.\n",
        "    #  We will use two fully connected layers\n",
        "    #  that connect to each other. We can\n",
        "    #  try more or less to see the impact\n",
        "    #  on our model.\n",
        "    #\n",
        "    fully_connected_1 = fully_connected_layer(flattened, 7 * 7 * 64, 1024,\n",
        "                                              \"Fully-connected_Layer_1\")\n",
        "    relu = tf.nn.relu(fully_connected_1)\n",
        "    embedding_input = relu\n",
        "    tf.summary.histogram(\"Fully-connected_Layer-1/relu\", relu)\n",
        "\n",
        "    embedding_size = 1024\n",
        "    logits = fully_connected_layer(fully_connected_1, 1024, 10,\n",
        "                                   \"Fully-connected_Layer_2\")\n",
        "\n",
        "    with tf.name_scope(\"Cross_Entropy\"):\n",
        "        cross_entropy = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=logits, labels=Y), name=\"cross_entropy\")\n",
        "\n",
        "        tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Train\"):\n",
        "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Accuracy\"):\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        tf.summary.scalar(\"Accuracy\", accuracy)\n",
        "\n",
        "    summ = tf.summary.merge_all()\n",
        "\n",
        "    #\n",
        "    #  Let's save embeddings so that they\n",
        "    #  are available in TensorBoard.\n",
        "    #\n",
        "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"Test_Embedding\")\n",
        "    assignment = embedding.assign(embedding_input)\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    #\n",
        "    #  We can now run our TensorFlow session.\n",
        "    #\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    writer = tf.summary.FileWriter(LOGDIR + name)\n",
        "    writer.add_graph(sess.graph)\n",
        "\n",
        "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
        "    embedding_config = config.embeddings.add()\n",
        "    embedding_config.tensor_name = embedding.name\n",
        "    embedding_config.sprite.image_path = SPRITES\n",
        "    embedding_config.metadata_path = LABELS\n",
        "\n",
        "    #\n",
        "    #  Create each thumbnail.\n",
        "    #\n",
        "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
        "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
        "\n",
        "    for i in tqdm.tqdm(range(epochs + 1), 'Epochs'):\n",
        "        batch = mnist.train.next_batch(100)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={X: batch[0], Y: batch[1]})\n",
        "            writer.add_summary(s, i)\n",
        "        if i % 500 == 0:\n",
        "            sess.run(assignment, feed_dict={\n",
        "                X: mnist.test.images[:1024],\n",
        "                Y: mnist.test.labels[:1024]\n",
        "            })\n",
        "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
        "\n",
        "        sess.run(train_step, feed_dict={X: batch[0], Y: batch[1]})\n",
        "\n",
        "    print('Done training!')\n",
        "    print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main runner function.\n",
        "\n",
        "    This calls the model function.\n",
        "    \"\"\"\n",
        "    print(\"\"\"\n",
        "    Running MNIST model with:\n",
        "\n",
        "        * Learning rate: {}\n",
        "        * Epochs: {}\n",
        "\n",
        "    \"\"\".format(LEARNING_RATE, EPOCHS))\n",
        "\n",
        "    mnist = load_data()\n",
        "    model(mnist=mnist, learning_rate=LEARNING_RATE, epochs=EPOCHS)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llVN4YvIqqF0"
      },
      "source": [
        "import matplotlib\n",
        "import pandas"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtc2MFSJptf_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}