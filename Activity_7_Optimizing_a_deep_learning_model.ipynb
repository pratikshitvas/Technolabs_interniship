{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 7: Optimizing a deep learning model\n",
    "In this activity we optimize our deep learning model. We aim to achieve greater performance than our model `bitcoin_lstm_v0`, which is off at about 6.8% from the real Bitcoin prices. We explore the following topics in this notebook:\n",
    "\n",
    "* Experimenting with different layers and the number of nodes\n",
    "* Grid search strategy for epoch and activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 5\n",
    "\n",
    "#  Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout, ActivityRegularization\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from scripts.utilities_activity7 import (\n",
    "    create_groups, split_lstm_input, \n",
    "    train_model, plot_two_series, rmse, \n",
    "    mape, denormalize)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load datasets\n",
    "train = pd.read_csv('data/train_dataset.csv')\n",
    "test = pd.read_csv('data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert `date` column to datetime type\n",
    "test['date'] = test['date'].apply(\n",
    "    lambda x: datetime.strptime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Group data into groups containing seven observations\n",
    "train_data = create_groups(\n",
    "    train['close_point_relative_normalization'][2:].values)\n",
    "test_data = create_groups(\n",
    "    test['close_point_relative_normalization'][:-3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reshape the data in the format expected by the LSTM layer\n",
    "X_train, Y_train = split_lstm_input(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "64da51"
   },
   "outputs": [],
   "source": [
    "#  TASK:\n",
    "#  Load data for `v0` of our model.\n",
    "#  Call this `model_v0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "56f346"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  TASK:\n",
    "#  Train the reference model `model_v0`.\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Layers and Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize variables\n",
    "period_length = 7\n",
    "number_of_periods = 76\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "309d7b"
   },
   "outputs": [],
   "source": [
    "#  Model 1: two LSTM layers\n",
    "model_v1 = Sequential()\n",
    "\n",
    "model_v1.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=True, stateful=False))   # note return_sequences is now true\n",
    "\n",
    "#  TASK:\n",
    "#  Add new LSTM layer to this network here.\n",
    "#\n",
    "\n",
    "\n",
    "model_v1.add(Dense(units=period_length))\n",
    "model_v1.add(Activation(\"linear\"))\n",
    "\n",
    "model_v1.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model=model_v1, X=X_train, Y=Y_train, epochs=100, version=1, run_number=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: two LSTM layers, trained for 300 epochs\n",
    "model_v2 = Sequential()\n",
    "\n",
    "model_v2.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=True, stateful=False))\n",
    "\n",
    "model_v2.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=False, stateful=False))\n",
    "\n",
    "model_v2.add(Dense(units=period_length))\n",
    "model_v2.add(Activation(\"linear\"))\n",
    "\n",
    "model_v2.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "2f8038"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  TASK:\n",
    "#  Change the number of epochs below\n",
    "#  to 300 and evaluate the results on TensorBoard.\n",
    "#\n",
    "train_model(model=model_v2, X=X_train, Y=Y_train, epochs=100, version=2, run_number=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "9e320f"
   },
   "outputs": [],
   "source": [
    "# Model 3: two LSTM layers, trained for 300 epochs,\n",
    "#          tanh activation function\n",
    "model_v3 = Sequential()\n",
    "\n",
    "model_v3.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=True, stateful=False))\n",
    "\n",
    "model_v3.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=False, stateful=False))\n",
    "\n",
    "model_v3.add(Dense(units=period_length))\n",
    "\n",
    "#  TASK:\n",
    "#  Change the activation function\n",
    "#  from \"linear\" to \"tanh\".\n",
    "#\n",
    "model_v3.add(Activation(\"linear\"))\n",
    "\n",
    "model_v3.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model=model_v3, X=X_train, Y=Y_train, epochs=300, version=3, run_number=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "87e31f"
   },
   "outputs": [],
   "source": [
    "model_v4 = Sequential()\n",
    "model_v4.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=True, stateful=False))\n",
    "\n",
    "#  TASK:\n",
    "#  Implement a Dropout() here.\n",
    "#\n",
    "\n",
    "\n",
    "model_v4.add(LSTM(\n",
    "    units=period_length,\n",
    "    batch_input_shape=(batch_size, number_of_periods, period_length),\n",
    "    input_shape=(number_of_periods, period_length),\n",
    "    return_sequences=False, stateful=False))\n",
    "\n",
    "#  TASK:\n",
    "#  Implement a Dropout() here too.\n",
    "#\n",
    "\n",
    "\n",
    "model_v4.add(Dense(units=period_length))\n",
    "model_v4.add(Activation(\"tanh\"))\n",
    "\n",
    "model_v4.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model=model_v4, X=X_train, Y=Y_train, epochs=600, version=4, run_number=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = np.concatenate((train_data, test_data), axis=1)\n",
    "\n",
    "def evaluate_model(model, kind='series'):\n",
    "    \"\"\"Compute the MSE for all future weeks in period.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Keras trained model\n",
    "    \n",
    "    kind: str, default 'series'\n",
    "        Kind of evaluation to perform. If 'series', \n",
    "        then the model will perform an evaluation \n",
    "        over the complete series.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    evaluated_weeks: list\n",
    "        List of MSE values for each evaluated\n",
    "        test week.\n",
    "    \"\"\"\n",
    "    if kind == 'series':\n",
    "        predicted_weeks = []\n",
    "        for i in range(0, test_data.shape[1]):\n",
    "            input_series = combined_set[0:,i:i+76]\n",
    "            predicted_weeks.append(model.predict(input_series))\n",
    "\n",
    "        predicted_days = []\n",
    "        for week in predicted_weeks:\n",
    "            predicted_days += list(week[0])\n",
    "\n",
    "        return predicted_days\n",
    "    else:\n",
    "        evaluated_weeks = []\n",
    "        for i in range(0, test_data.shape[1]):\n",
    "            input_series = combined_set[0:,i:i+77]\n",
    "\n",
    "            X_test = input_series[0:,:-1].reshape(1, input_series.shape[1] - 1, 7)\n",
    "            Y_test = input_series[0:,-1:][0]\n",
    "\n",
    "            result = model.evaluate(x=X_test, y=Y_test, verbose=0)\n",
    "            evaluated_weeks.append(result)\n",
    "            \n",
    "            return evaluated_weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekly_mse(series, model_name, color):\n",
    "    \"\"\"Plot weekly MSE.\"\"\"\n",
    "    ax = pd.Series(series).plot(drawstyle=\"steps-post\",\n",
    "                                figsize=(14,4),\n",
    "                                color=color,\n",
    "                                grid=True,\n",
    "                                label=model_name,\n",
    "                                alpha=0.7,\n",
    "                                title='Mean Squared Error (MSE) for Test Data (all models)'.format(\n",
    "                                       model_name))\n",
    "\n",
    "    ax.set_xticks(range(0, len(series)))\n",
    "    ax.set_xlabel(\"Predicted Week\")\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekly_predictions(predicted_days, name, display_plot=True, \n",
    "                            variable='close'):\n",
    "    \"\"\"Plot weekly predictions and calculate RMSE and MAPE.\"\"\"\n",
    "    \n",
    "    # Create dataframe to store predictions and associated dates\n",
    "    last_day = datetime.strptime(train['date'].max(), '%Y-%m-%d')\n",
    "    list_of_days = []\n",
    "    for days in range(1, len(predicted_days) + 1):\n",
    "        D = (last_day + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "        list_of_days.append(D)\n",
    "    \n",
    "    predicted = pd.DataFrame({\n",
    "        'date': list_of_days,\n",
    "        'close_point_relative_normalization': predicted_days\n",
    "    })\n",
    "    \n",
    "    # Convert `date` variable to datetime\n",
    "    predicted['date'] = predicted['date'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "    # Create iso_week column in `predicted` dataframe\n",
    "    predicted['iso_week'] = predicted['date'].apply(\n",
    "        lambda x: x.strftime('%Y-%U'))\n",
    "\n",
    "    # Denormalize predictions\n",
    "    predicted_close = predicted.groupby('iso_week').apply(\n",
    "        lambda x: denormalize(test[:-3], x))\n",
    "\n",
    "    # Plot denormalized predictions and observed values\n",
    "    plot_two_series(test[:-3], predicted_close,\n",
    "                    variable=variable,\n",
    "                    title=f'{name}: Predictions per Week')\n",
    "    \n",
    "    # Calculate RMSE and MAPE\n",
    "    print(f'RMSE: {rmse(test[:-3][variable], predicted_close[variable]):.2f}')\n",
    "    print(f'MAPE: {mape(test[:-3][variable], predicted_close[variable]):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Evaluate each model trained in this activity in sequence\n",
    "models = [model_v0, model_v1, model_v2, model_v3, model_v4]\n",
    "for i, M in enumerate(models):\n",
    "    predicted_days = evaluate_model(M, kind='series')\n",
    "    plot_weekly_predictions(predicted_days, f'model_v{i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
